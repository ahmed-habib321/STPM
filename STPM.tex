\documentclass[]{article}


\input{MyTools}
\usepackage{fancyhdr}
\usepackage{fontspec}
\usepackage{physics}


%\definecolor{cover}{RGB}{230, 194, 24}
\definecolor{cover}{RGB}{51,215,213}
\newfontfamily\Acmefont{Acme-Regular}[
        Path = fonts/Acme/,
        Extension =.ttf
]
\newfontfamily\fancyfont{GreatVibes-Regular}[
        Path = fonts/Great_Vibes/,
        Extension =.ttf
]
\newfontfamily\handfont{PlaypenSans-ExtraBold}[
        Path = fonts/Playpen_Sans/,
        Extension =.ttf
]
\newfontfamily\Garamondfont{EBGaramond-Medium}[
        Path = fonts/Garamond/,
        Extension =.ttf
]

\begin{document}

\include{SoloLecStarter}   %When making solo lecture remove the comment
%\include{BookStarter}      %The pages in the front
%\include{BookBody}         %The content of the book

\section{Generalized Inverse}

In the classical sence of linear algebra, an $n$-by-$n$ square matrix $A$ is 
called invertible also nonsingular 
if there exists an $n$-by-$n$ square matrix B such that
\[
AB = BA = I_n        
\]
If this is the case, then the matrix $B$ is 
uniquely determined by $A$, and is called the 
inverse of $A$, denoted by $A^{-1}$
\\
In linear algebra for matrix $A$ to own an inverse 
it had to be square matrix and nonsingular \\ (i.e $\det(A)\neq0$)
\\
Let us now study the case for any matrix of order $(m\times n)$ \\
we define the generalized inverse $A^{+}$
\begin{align*}
        \circled{I}& \dquad AA^{+}A = A
        \\
        \circled{II}& \dquad \exists  U,V \quad \text{s.t} \quad A^{+} = UA^{*} \quad,\quad A^{+} = A^{*}V
\end{align*}
where $A^{*}$ is the conjugate transpose if all elements of $A$ are real then $A^{*} = A^{\operatorname{T}}$
\[
A = \begin{pmatrix}
        1+2i & 3-i\\
        5 & 6i \\
    \end{pmatrix}
\quad\Longrightarrow \quad
A^{*} = \begin{pmatrix}
        1-2i & 5\\
        3+i & -6i \\
    \end{pmatrix}
\]
\begin{theorem}[The existence and uniqueness of GI]
        for matrix $A$ of order $(m\times n)$ the generalized inverse $A^{+}$ exists ,and it's unique
\end{theorem}
\begin{proof}[Proof the uniqueness]
        suppose that there is two generalized inverse $A_1^{+}$ , $A_2^{+}$ thus
        \begin{align*}
                \circled{I}& \dquad AA_i^{+}A = A
                \\
                \circled{II}& \dquad \exists  U_i,V_i \quad \text{s.t} \quad A_i^{+} = U_i A^{*} \quad,\quad A^{+} = A_i^{*}V_i \dquad \text{for }i=1,2
        \end{align*}
from \circled{I} 
\begin{align*}
        A[A_2^{+}-A_1^{+}]A =& 0
        \\
        AD^{+}A=&0
\end{align*}
where $D^{+} = A_2^{+}-A_1^{+}$ and we can say that 
\begin{equation*}
        \begin{aligned}[c]
            &D^{+} = A^{*}V
            \\
            &V = V_2-V_1
        \end{aligned}
        \qquad\qquad
        \begin{aligned}[c]
        &D^{+} = UA^{*}
        \\
        &U = U_2-U_1
        \end{aligned}
    \end{equation*}
now
\begin{align*}
        (D^{+}A)^{*}D^{+}A &= A^* D^{+^{\textstyle *}} D^{+} A
        \\
        &= A^* V^{*}A D^{+} A = 0
\end{align*}
because $AD^{+}A=0$, then we get 
\begin{align*}
        (D^{+}A)^{*}D^{+}A &= 0
        \\
        D^{+}A &= 0
        \\
        D^{+}A U^*&= 0
        \\
        D^{+}D^{+^{\textstyle *}}&= 0
        \\
        \therefore D^{+} &= 0
        \\
        A_2^{+}-A_1^{+} &= 0
        \\
        A_2^{+} &=A_1^{+}
\end{align*}
\end{proof}
\begin{proof}[Proof the existence synthetically]
Let $A$ be a non square matrix we can write $A = BC$ where
        \begin{align*}
                A &\text{ is of order } (m\times n)
                \\
                B &\text{ is of order } (m\times r)
                \\
                C &\text{ is of order } (r\times n)
        \end{align*}
set
        \begin{equation*}
                \begin{cases}
                        \displaystyle \Lambda = C^{*}(CC^{*})^{-1}(B^{*}B)^{-1}B^{*}
                        \\
                        \displaystyle U = C^{*}(CC^{*})^{-1}(B^{*}B)^{-1}(CC^{*})^{-1}C
                        \\
                        \displaystyle V = B(B^{*}B)^{-1}(CC^{*})^{-1}(B^{*}B)^{-1}B^{*}
                    \end{cases}
        \end{equation*}
we can see that 
        \begin{align*}
                A\Lambda A &= BCC^{*}(CC^{*})^{-1}(B^{*}B)^{-1}B^{*}BC
                \\
                &= B\underbrace{\left[CC^{*}(CC^{*})^{-1}\right]}_{I}\underbrace{\left[(B^{*}B)^{-1}B^{*}B\right]}_{I}C
                \\
                &= BC = A
        \end{align*}
now to proof the property \circled{II}
\begin{align*}
        UA^* &=  C^{*}(CC^{*})^{-1}(B^{*}B)^{-1}(CC^{*})^{-1}C C^* B^*
        \\
        &=  C^{*}(CC^{*})^{-1}(B^{*}B)^{-1}\underbrace{\left[(CC^{*})^{-1}C C^*\right]}_{I} B^*
        \\
        &= C^{*}(CC^{*})^{-1}(B^{*}B)^{-1}B^* = \Lambda
        \\
        \\
        A^*V &=  C^* B^*B(B^{*}B)^{-1}(CC^{*})^{-1}(B^{*}B)^{-1}B^{*}
        \\
        &=  C^{*}\underbrace{\left[B^*B(B^{*}B)^{-1}\right]}_{I}(CC^{*})^{-1}(B^{*}B)^{-1}B^{*}
        \\
        &= C^{*}(CC^{*})^{-1}(B^{*}B)^{-1}B^* = \Lambda
\end{align*}
thus $\Lambda = A^{+} $ is the generalized inverse
\end{proof}

\begin{lemma}
        $B^{*}B$,$CC^{*}$ are square matrices and $\det(B^{*}B) ,\det(CC^{*}) \neq 0 $
\end{lemma}
\begin{proof}[Proof]
        it's clear that $B^{*}B$,$CC^{*}$ are square matrices of order $r$ now to proof that 
        $\det(B^{*}B) ,\det(CC^{*}) \neq 0 $\\
        consider the homogeneous system

        \[
        B^{*}B X = 0  \dquad,\dquad X = \begin{pmatrix}
        x_1\\
        x_2\\
        \vdots\\
        x_r\\
        \end{pmatrix}        
        \]
we have that 
        \begin{align*}
                B^{*}B X &= 0
                \\
                X^{*}B^{*}B X &= 0
                \\
                (BX)^{*}BX &= 0
        \end{align*}
set $BX = Y$
        \begin{align*}
                Y^{*}Y &= 0
                \\
                y_1^{2} + y_2^{2} + \dots + y_r^{2} &= 0
                \\
                y_1^{2} = y_2^{2} = \dots = y_r^{2} &= 0
                \\
                \Longrightarrow BX &= 0 
        \end{align*}
this means that only the trevial solution solves this equation
\\
but $\rank(B)=r=$number of unknowns therefore $x_1 = x_2 = \dots = x_r = 0$
also $\rank(B^{*}B)=r$ then $\det(B^{*}B) \neq 0$
\end{proof}

\begin{example}
        find $A^{+}$ if 
        \[
        A = \begin{pmatrix}
                1 & 1 & 4\\
                2 & 1 & 2\\
            \end{pmatrix} 
            = 
            \underbrace{
                \begin{pmatrix}
                        1 & 0\\
                        0 & 1\\
                    \end{pmatrix}
            }_B
            \underbrace{
                \begin{pmatrix}
                        1 & 1 & 4\\
                        2 & 1 & 2\\
                    \end{pmatrix} 
            }_C
        \]
we have taken $B = I$ to make the calculation easier but most of the time it doesn't work 
\\
only works if $\det(AA^{*}) \neq 0$ in case of $\det(AA^{*}) = 0$ you need to find two matrices $B,C$ s.t
$BC = A$ and $\det(CC^{*}) , \det(B^{*}B) \neq 0$
        \begin{align*}
                A^{+} &=  C^{*}(CC^{*})^{-1} (B^{*}B)^{-1}B^{*} =  A^{*}(AA^{*})^{-1}
                \\
                &=
                \begin{pmatrix}
                        1 & 2\\
                        1 & 1\\
                        4 & 2
                    \end{pmatrix} 
                \left[
                        \begin{pmatrix}
                                1 & 1 & 4\\
                                2 & 1 & 2\\
                        \end{pmatrix} 
                        \begin{pmatrix}
                                1 & 2\\
                                1 & 1\\
                                4 & 2
                        \end{pmatrix}   
                \right]^{-1}
                \\
                &=
                \begin{pmatrix}
                        1 & 2\\
                        1 & 1\\
                        4 & 2
                    \end{pmatrix} 
                        \begin{pmatrix}
                                18 & 11\\
                                11 & 9\\
                        \end{pmatrix}^{-1}
                \\
                &=
                \begin{pmatrix}
                        1 & 2\\
                        1 & 1\\
                        4 & 2
                \end{pmatrix} 
                \begin{pmatrix}
                        \displaystyle \frac{9}{41} & \displaystyle  \frac{-11}{41}\\\\
                        \displaystyle \frac{-11}{41} & \displaystyle   \frac{18}{41}\\
                \end{pmatrix}   
                \\
                &=
                \begin{pmatrix}
                        \displaystyle \frac{-13}{41} & \displaystyle \frac{25}{41}\\\\
                        \displaystyle \frac{-2}{41} & \displaystyle \frac{7}{41}\\\\
                        \displaystyle \frac{14}{41} & \displaystyle \frac{-8}{41}
                \end{pmatrix}
                \\
                AA^{+} &= \begin{pmatrix}
                        1 & 1 & 4\\
                        2 & 1 & 2\\
                    \end{pmatrix} \begin{pmatrix}
                        \displaystyle \frac{-13}{41} & \displaystyle \frac{25}{41}\\\\
                        \displaystyle \frac{-2}{41} & \displaystyle \frac{7}{41}\\\\
                        \displaystyle \frac{14}{41} & \displaystyle \frac{-8}{41}
                \end{pmatrix} = \begin{pmatrix}
                        1 & 0 \\
                        0 & 1 \\
                    \end{pmatrix}
        \end{align*}
$
\begin{pmatrix}
        \displaystyle \frac{-13}{41} & \displaystyle \frac{25}{41}\\\\
        \displaystyle \frac{-2}{41} & \displaystyle \frac{7}{41}\\\\
        \displaystyle \frac{14}{41} & \displaystyle \frac{-8}{41}
\end{pmatrix}
$ is the right inverse of $A$
\\
notice that if you take $B = A$ and $C = I$ will not give an answer because $\det(A^{*}A) = 0$
\end{example}



\begin{enrichment}{Roger Penrose}{Roger_Penrose.jpg}{2.4}{.8}{.17}
        Sir Roger Penrose is a British mathematical physicist, mathematician, and philosopher 
        who has made significant contributions to various fields, including general relativity, 
        cosmology, and the foundations of quantum mechanics. \\
        Penrose has made significant contributions to the fields of mathematics
        One of Penrose's notable contributions is his work on the generalized inverse of a matrix, 
        Penrose introduced the concept of the Moore-Penrose pseudoinverse, 
        which is a widely used method for finding a generalized inverse of a matrix. 
        This pseudoinverse has applications in various areas, including linear algebra, 
        statistics, signal processing, and machine learning.
\end{enrichment}
\begin{enrichment}{E.H. Moore}{moore.jpg}{2.4}{.8}{.17}
        Eliakim Hastings Moore (1862–1932) was an American mathematician known for his contributions to algebra and mathematical logic. 
        One of his significant contributions was in the field of linear algebra, 
        particularly his work on the generalized inverse of a non-square matrix.
        The Moore–Penrose inverse is a concept that extends the idea of the matrix inverse to non-square matrices.
        The Moore–Penrose generalized inverse is perhaps the most well-known and widely used among 
        various generalizations of the matrix inverse for non-square matrices. 
        It has applications in solving linear systems of equations, 
        least squares problems, and in situations where the original matrix might not have a unique inverse.
\end{enrichment}

\begin{proof}[Proof the existence analytically]
        Let $A$ be a non square matrix we can write $A = BC$ where
        \begin{align*}
                A &\text{ is of order } (m\times n)
                \\
                B &\text{ is of order } (m\times r)
                \\
                C &\text{ is of order } (r\times n)
        \end{align*}
        let us try to find two matrices such $B^{+} , Q$ that 
        \[
        BB^{+} B = B \quad,\quad B^{+} = QB^*
        \]
        we notice that 
        \[
        BQB^{*}B = B \quad,\quad B^{*}BQB^{*}B = B^{*}B
        \]
        since $\det(B^{*}B) \neq 0$ and $B^{*}B$ is square thus $Q$ is the ordinary inverse of $B^{*}B$
        \[
        Q = {(B^{*}B)}^{-1}
        \]
        thus 
        \[
        B^{+} = {(B^{*}B)}^{-1}B^*  
        \]
        similarly
        \[
        C^{+} = C^*{(C^{*}C)}^{-1}
        \]
        which makes that 
        \[
        A^{+}  = C^{+}B^{+}= C^*{(C^{*}C)}^{-1}{(B^{*}B)}^{-1}B^*
        \]
        the rest of the proof as in the synthetically part 
\end{proof}
\begin{enrichment*}{Synthetic Proofs}
        Synthetic proofs in mathematics refer to a style of proof that relies on creative and constructive methods rather than analytical or deductive reasoning. In a synthetic proof, mathematicians often use geometric or intuitive arguments to establish the truth of a statement. This approach involves constructing figures, diagrams, or models that illustrate the relationships and properties relevant to the mathematical concept being proven.
\end{enrichment*}
\begin{enrichment*}{Analytic Proofs}
        Analytic proofs, in the context of mathematics, refer to a method of proof that relies on logical reasoning and the application of established mathematical principles and definitions. The term "analytic" is derived from "analysis," emphasizing the breakdown of a mathematical statement or proposition into simpler, well-understood components.
\end{enrichment*}

%\include{BookEnd}          %The pages in the End
\end{document}